{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "06459455",
   "metadata": {},
   "source": [
    "# Importing and downloading the NLTK resources"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c45eb14e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\Ramesh\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\Ramesh\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\Ramesh\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "import string\n",
    "import unicodedata\n",
    "\n",
    "# Download NLTK resources\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')\n",
    "nltk.download('wordnet') "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9b7111d",
   "metadata": {},
   "source": [
    "# 1. What is the purpose of text preprocessing in NLP, and why is it essential before analysis?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc705ac7",
   "metadata": {},
   "source": [
    "The purpose of text preprocessing in Natural Language Processing (NLP) is like getting a text ready for analysis. It cleans and organizes the raw text data before it is used for analysis. Text data when sourced from various documents or web sources, often contains noise, irrelevant information, and inconsistencies. Text preprocessing aims to transform this raw text into a format that is more suitable for machine learning or other natural language processing tasks.\n",
    "\n",
    "\n",
    "The key reasons why text preprocessing is essential before analysis include:\n",
    "\n",
    "    - Noise Reduction\n",
    "    - Normalization\n",
    "    - Tokenization\n",
    "    - Removing Stop Words\n",
    "    - Stemming or Lemmatization\n",
    "    - Handling Punctuation and Special Characters\n",
    "    - Vectorization"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eacfd3c9",
   "metadata": {},
   "source": [
    "# 2. Describe tokenization in NLP and explain its significance in text processing."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ccf92278",
   "metadata": {},
   "source": [
    "Tokenization in Natural Language Processing (NLP) is the process of breaking down a sentence into individual words or pieces. It is important because it helps computer understand and work with the structure of the text.\n",
    "\n",
    "\n",
    "The significance of tokenization in text processing involves:\n",
    "       \n",
    "    - Text Segmentation\n",
    "    - Word Level Analysis\n",
    "    - Feature Extraction\n",
    "    - Vocabulary Creation\n",
    "    - Statistical Analysis\n",
    "    - Preprocessing for Further Tasks\n",
    "    - Text Comparison and Retrieval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d5e2dc89",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Tokenization', 'is', 'important', 'in', 'NLP', '.']\n"
     ]
    }
   ],
   "source": [
    "# Example of Tokenization\n",
    "text = \"Tokenization is important in NLP.\"\n",
    "tokens = word_tokenize(text)\n",
    "print(tokens)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b2d950e",
   "metadata": {},
   "source": [
    "# 3. What are the differences between stemming and lemmatization in NLP? When would you choose one over the other?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b09a7484",
   "metadata": {},
   "source": [
    "Stemming: It is a process of reducing words to their base or root form by removing suffixes. The result may not always be a valid word.\n",
    "\n",
    "Example: Running → Run, Jumps → Jump, Better → Bet\n",
    "\n",
    "Lemmatization: It involves reducing words to their base or root form, but it considers the meaning of the word and ensures that the resulting word is valid and found in the dictionary.\n",
    "\n",
    "Example: Running → Run, Jumps → Jump, Better → Good"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fc45a13",
   "metadata": {},
   "source": [
    "\n",
    "When to Choose:\n",
    "\n",
    "Stemming: Use stemming when you need a fast and approximate representation of words. It is suitable for tasks where speed is crucial, such as information retrieval or text mining. However, it may sacrifice precision for speed.\n",
    "\n",
    "Lemmatization: Choose lemmatization when you require a more accurate representation of words, especially in tasks where the meaning of words is crucial, such as question answering, sentiment analysis, or language translation. Lemmatization tends to be slower but provides a more linguistically valid result."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "355014c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stemmed Words: ['run', 'jump', 'better', 'than', 'walk', 'when', 'you', \"'re\", 'run', '.']\n",
      "Lemmatized Words: ['running', 'jump', 'better', 'than', 'walk', 'when', 'you', \"'re\", 'running', '.']\n"
     ]
    }
   ],
   "source": [
    "from nltk.stem import PorterStemmer, WordNetLemmatizer\n",
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "# Sample text\n",
    "text = \"Running jumps better than walks when you're running.\"\n",
    "\n",
    "# Tokenization\n",
    "tokens = word_tokenize(text)\n",
    "\n",
    "# Stemming\n",
    "porter_stemmer = PorterStemmer()\n",
    "stemmed_words = [porter_stemmer.stem(word) for word in tokens]\n",
    "print(\"Stemmed Words:\", stemmed_words)\n",
    "\n",
    "# Lemmatization with lowercase conversion\n",
    "wordnet_lemmatizer = WordNetLemmatizer()\n",
    "lemmatized_words = [wordnet_lemmatizer.lemmatize(word.lower()) for word in tokens]\n",
    "print(\"Lemmatized Words:\", lemmatized_words)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b861aabd",
   "metadata": {},
   "source": [
    "# 4. Explain the concept of stop words and their role in text preprocessing. How do they impact NLP tasks?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "313bf7aa",
   "metadata": {},
   "source": [
    "Stop words are common words that are often filtered out during text preprocessing because they are considered to be of little value in understanding the meaning of a document. These words are highly frequent in a language but typically do not contribute much to the overall context or semantics of a sentence. Examples of stop words include \"the,\" \"and,\" \"is,\" \"of,\" etc. Removing them is like cleaning up noise in your text.\n",
    "\n",
    "The role of stop words in text preprocessing is primarily to improve the efficiency and effectiveness of natural language processing (NLP) tasks. \n",
    "\n",
    "The impact on NLP tasks can be on:\n",
    "\n",
    "   - Efficiency\n",
    "   - Focus on Meaningful Words\n",
    "   - Dimensionality Reduction\n",
    "   - Improved Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a6ef7bfe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original Tokens: ['This', 'is', 'an', 'example', 'sentence', 'with', 'some', 'stop', 'words', '.']\n",
      "Tokens after Removing Stop Words: ['example', 'sentence', 'stop', 'words', '.']\n"
     ]
    }
   ],
   "source": [
    "text = \"This is an example sentence with some stop words.\"\n",
    "\n",
    "# Tokenization\n",
    "tokens = word_tokenize(text)\n",
    "\n",
    "# Remove stop words\n",
    "stop_words = set(stopwords.words('english'))\n",
    "filtered_text = [word for word in tokens if word.lower() not in stop_words]\n",
    "\n",
    "print(\"Original Tokens:\", tokens)\n",
    "print(\"Tokens after Removing Stop Words:\", filtered_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35761ec0",
   "metadata": {},
   "source": [
    "# 5. How does the process of removing punctuation contribute to text preprocessing in NLP? What are its benefits?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e6fa166",
   "metadata": {},
   "source": [
    "The process of removing punctuation in text preprocessing for Natural Language Processing (NLP) offers several benefits, including simplifying the text and making it more consistent.\n",
    "\n",
    "It's benefits are:\n",
    "\n",
    "   - Simplification\n",
    "   - Consistency\n",
    "   - Improved Tokenization\n",
    "   - Enhanced Model Performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "770a6e72",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original Text: This is an example sentence! With some punctuation.\n",
      "Text after Removing Punctuation: This is an example sentence With some punctuation\n"
     ]
    }
   ],
   "source": [
    "import string\n",
    "\n",
    "# Sample text with punctuation\n",
    "text_with_punctuation = \"This is an example sentence! With some punctuation.\"\n",
    "\n",
    "# Removing punctuation\n",
    "cleaned_text = text_with_punctuation.translate(str.maketrans(\"\", \"\", string.punctuation))\n",
    "\n",
    "print(\"Original Text:\", text_with_punctuation)\n",
    "print(\"Text after Removing Punctuation:\", cleaned_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ab976b8",
   "metadata": {},
   "source": [
    "# 6. Discuss the importance of lowercase conversion in text preprocessing. Why is it a common step in NLP tasks?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d171ebc6",
   "metadata": {},
   "source": [
    "Importance: \n",
    "It ensures all text is in the same format. Computers might treat \"Word\" and \"word\" differently. Making everything lowercase avoids this issue.\n",
    "\n",
    "Here are some reasons why lowercase conversion is crucial:\n",
    "\n",
    "  - Consistency\n",
    "  - Avoidance of Redundancy\n",
    "  - Improved Matching\n",
    "  - Enhanced Model Generalization\n",
    "  - Compatibility with NLP Libraries\n",
    "  - Reduced Vocabulary Size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0c09f008",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original Text: This is an Example.\n",
      "Text after Lowercase Conversion: this is an example.\n"
     ]
    }
   ],
   "source": [
    "# Sample text with mixed case\n",
    "text_to_lower = \"This is an Example.\"\n",
    "\n",
    "# Lowercase conversion\n",
    "lowercase_text = text_to_lower.lower()\n",
    "\n",
    "print(\"Original Text:\", text_to_lower)\n",
    "print(\"Text after Lowercase Conversion:\", lowercase_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69bcaccf",
   "metadata": {},
   "source": [
    "# 7. Explain the term \"vectorization\" concerning text data. How does techniques like CountVectorizer contribute to text preprocessing in NLP?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61e1b14d",
   "metadata": {},
   "source": [
    "Vectorization in the context of text data refers to the process of converting textual information into numerical vectors that can be used by machine learning models. It is a crucial step in preparing text data for analysis and machine learning algorithms, as these algorithms typically require numerical input. Vectorization allows us to represent words, phrases, or entire documents as numerical features, enabling the application of various statistical and machine learning techniques to analyze and model natural language.\n",
    "\n",
    "One common technique for vectorization in NLP is the use of the CountVectorizer. CountVectorizer converts a collection of text documents into a matrix of token counts, where each row corresponds to a document, and each column corresponds to a unique word in the entire corpus. The values in the matrix represent the frequency of each word in each document."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d50d0201",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1 1 1 0 1 1]\n",
      " [2 0 1 1 1 1]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "# Sample corpus\n",
    "corpus = [\"This is the first document.\", \"This document is the second document.\"]\n",
    "\n",
    "# Create CountVectorizer instance\n",
    "vectorizer = CountVectorizer()\n",
    "\n",
    "# Transform the corpus into a document-term matrix\n",
    "X = vectorizer.fit_transform(corpus)\n",
    "\n",
    "# Display the document-term matrix\n",
    "print(X.toarray())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f503424",
   "metadata": {},
   "source": [
    "# 8. Describe the concept of normalization in NLP. Provide examples of normalization techniques used in text preprocessing."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02693488",
   "metadata": {},
   "source": [
    "In Natural Language Processing (NLP), normalization refers to the process of transforming text data into a standard and consistent format. The goal is to handle variations in the text and ensure that similar text patterns are represented in the same way. Normalization is essential for improving the accuracy and effectiveness of various NLP tasks by reducing noise and inconsistencies in the data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64740b6b",
   "metadata": {},
   "source": [
    "Common normalization techniques in text preprocessing include:\n",
    "    \n",
    "Lowercasing: Converting all text to lowercase ensures uniformity in the representation of words. This helps in treating words with different cases as identical, avoiding redundancy and inconsistencies.\n",
    "\n",
    "Removing Accents and Diacritics: Removing accents and diacritics ensures that words with or without accents are treated the same way. This is particularly relevant in languages with accented characters.\n",
    "\n",
    "Handling Contractions: Expanding contractions involves replacing shortened forms of words with their full forms. This step can reduce vocabulary size and improve consistency.\n",
    "\n",
    "Removing Special Characters and Numbers: Removing special characters and numbers simplifies the text and focuses on the linguistic content. This step is common when the presence of such characters is irrelevant to the analysis.\n",
    "\n",
    "Stemming and Lemmatization: Reducing words to their base or root form through stemming or lemmatization helps in normalizing variations in word morphology. It is particularly useful for tasks where word meaning is crucial."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "18b94b2a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "this is an example.\n"
     ]
    }
   ],
   "source": [
    "# Lowercasing\n",
    "\n",
    "text = \"This is an Example.\"\n",
    "normalized_text = text.lower()\n",
    "print(normalized_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "992b0d23",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cafe and cafe are the same.\n"
     ]
    }
   ],
   "source": [
    "# Removing Accents and Diacritics\n",
    "\n",
    "import unicodedata\n",
    "\n",
    "text_with_accents = \"Café and café are the same.\"\n",
    "normalized_text = unicodedata.normalize('NFKD', text_with_accents).encode('ASCII', 'ignore').decode('utf-8')\n",
    "print(normalized_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "787221ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I cannot believe it is raining.\n"
     ]
    }
   ],
   "source": [
    "# Handling Contractions\n",
    "\n",
    "import contractions\n",
    "\n",
    "text_with_contractions = \"I can't believe it's raining.\"\n",
    "normalized_text = contractions.fix(text_with_contractions)\n",
    "print(normalized_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "86be47e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This is an example with numbers  and special characters \n"
     ]
    }
   ],
   "source": [
    "# Removing Special Characters and Numbers\n",
    "\n",
    "import re\n",
    "\n",
    "text_with_special_chars = \"This is an example with numbers 123 and special characters @#!\"\n",
    "normalized_text = re.sub(r'[^a-zA-Z\\s]', '', text_with_special_chars)\n",
    "print(normalized_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "735b5bc3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stemmed Words: ['run', 'jump', 'better', 'than', 'walk', 'when', 'you', \"'re\", 'run', '.']\n",
      "Lemmatized Words: ['Running', 'jump', 'better', 'than', 'walk', 'when', 'you', \"'re\", 'running', '.']\n"
     ]
    }
   ],
   "source": [
    "# Stemming and Lemmatization\n",
    "\n",
    "from nltk.stem import PorterStemmer, WordNetLemmatizer\n",
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "text = \"Running jumps better than walks when you're running.\"\n",
    "\n",
    "# Tokenization\n",
    "tokens = word_tokenize(text)\n",
    "\n",
    "# Stemming\n",
    "porter_stemmer = PorterStemmer()\n",
    "stemmed_words = [porter_stemmer.stem(word) for word in tokens]\n",
    "print(\"Stemmed Words:\", stemmed_words)\n",
    "\n",
    "# Lemmatization\n",
    "wordnet_lemmatizer = WordNetLemmatizer()\n",
    "lemmatized_words = [wordnet_lemmatizer.lemmatize(word) for word in tokens]\n",
    "print(\"Lemmatized Words:\", lemmatized_words)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
