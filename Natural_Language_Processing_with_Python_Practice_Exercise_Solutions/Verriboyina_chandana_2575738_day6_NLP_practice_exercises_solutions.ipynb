{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "adccf042",
   "metadata": {},
   "source": [
    "# 1. Build a NLP Language model for text generation involves train a neural network to predict the next word in a sequence of words."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "872bd31d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SIRISHA\\anaconda3\\Lib\\site-packages\\transformers\\generation\\configuration_utils.py:386: UserWarning: `do_sample` is set to `False`. However, `top_p` is set to `0.95` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_p`.\n",
      "  warnings.warn(\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Text: Once upon a time, it was said, there was a man in the house of the Lord, and he said to him, \"Lord, I have heard that there is a woman in this house. She is the daughter of Joseph.\" And Joseph said unto the woman, Behold, she is my wife.\n",
      "\n",
      "And the man answered, Yea, but ye have not seen her, for she hath not come unto me. And he took her and put her in his hand, saying\n"
     ]
    }
   ],
   "source": [
    "from transformers import GPT2LMHeadModel, GPT2Tokenizer\n",
    "import torch\n",
    "\n",
    "# Load pre-trained model and tokenizer\n",
    "model = GPT2LMHeadModel.from_pretrained(\"gpt2\")\n",
    "tokenizer = GPT2Tokenizer.from_pretrained(\"gpt2\")\n",
    "\n",
    "# Generate text\n",
    "input_text = \"Once upon a time\"\n",
    "input_ids = tokenizer.encode(input_text, return_tensors=\"pt\")\n",
    "\n",
    "# Generate multiple words\n",
    "output = model.generate(input_ids, max_length=100, num_beams=5, no_repeat_ngram_size=2, top_k=50, top_p=0.95)\n",
    "\n",
    "# Convert the generated output tensor to a list\n",
    "generated_text = tokenizer.decode(output[0], skip_special_tokens=True)\n",
    "\n",
    "print(\"Generated Text:\", generated_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "763a9e09",
   "metadata": {},
   "source": [
    "# The other way is:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a3d35451",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\Ramesh\\AppData\\Roaming\\Python\\Python311\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dense, Embedding\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "86c58f2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "text_data = [\"I woke up this morning feeling an overwhelming sense of joy. The sun streamed through the window, casting a warm glow that filled me with happiness. As I stepped outside, a gentle breeze brushed against my skin, evoking a sense of calm and contentment. However, as the day progressed, a wave of nostalgia washed over me, reminding me of cherished memories from the past. I found myself smiling at old photographs, feeling a mix of joy and longing.Suddenly, a pang of sadness hit me as I remembered missed opportunities and lost connections. Yet, hope flickered within me, like a small flame refusing to be extinguished. Determination surged through my veins, propelling me forward despite the obstacles. Later, an unexpected surprise lifted my spirits, filling me with excitement and anticipation for what lay ahead. Ultimately, today has been a whirlwind of emotions, each one leaving its mark on my heart.\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fb26df19",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tokenize the text\n",
    "tokenizer = Tokenizer()\n",
    "tokenizer.fit_on_texts(text_data)\n",
    "total_words = len(tokenizer.word_index) + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f9cf3dc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_sequences = []\n",
    "for line in text_data:\n",
    "    token_list = tokenizer.texts_to_sequences([line])[0]\n",
    "    for i in range(1, len(token_list)):\n",
    "        n_gram_sequence = token_list[:i+1]\n",
    "        input_sequences.append(n_gram_sequence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d7cbfd08",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_sequence_len = max([len(seq) for seq in input_sequences])\n",
    "input_sequences = np.array(pad_sequences(input_sequences, maxlen=max_sequence_len, padding='pre'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0c61850a",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = input_sequences[:, :-1]\n",
    "labels = input_sequences[:, -1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8f210d2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.utils import to_categorical\n",
    "y = to_categorical(labels, num_classes=total_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e06e19f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\Ramesh\\AppData\\Roaming\\Python\\Python311\\site-packages\\keras\\src\\backend.py:873: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Embedding(total_words, 100, input_length=max_sequence_len-1))\n",
    "model.add(LSTM(150))\n",
    "model.add(Dense(total_words, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "23eab1cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\Ramesh\\AppData\\Roaming\\Python\\Python311\\site-packages\\keras\\src\\optimizers\\__init__.py:309: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3424b73f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "WARNING:tensorflow:From C:\\Users\\Ramesh\\AppData\\Roaming\\Python\\Python311\\site-packages\\keras\\src\\utils\\tf_utils.py:492: The name tf.ragged.RaggedTensorValue is deprecated. Please use tf.compat.v1.ragged.RaggedTensorValue instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\Ramesh\\AppData\\Roaming\\Python\\Python311\\site-packages\\keras\\src\\engine\\base_layer_utils.py:384: The name tf.executing_eagerly_outside_functions is deprecated. Please use tf.compat.v1.executing_eagerly_outside_functions instead.\n",
      "\n",
      "5/5 [==============================] - 3s 103ms/step - loss: 4.7109 - accuracy: 0.0067\n",
      "Epoch 2/50\n",
      "5/5 [==============================] - 1s 99ms/step - loss: 4.6938 - accuracy: 0.0738\n",
      "Epoch 3/50\n",
      "5/5 [==============================] - 0s 97ms/step - loss: 4.6726 - accuracy: 0.0872\n",
      "Epoch 4/50\n",
      "5/5 [==============================] - 0s 92ms/step - loss: 4.5839 - accuracy: 0.0671\n",
      "Epoch 5/50\n",
      "5/5 [==============================] - 0s 92ms/step - loss: 4.5270 - accuracy: 0.0268\n",
      "Epoch 6/50\n",
      "5/5 [==============================] - 0s 88ms/step - loss: 4.4494 - accuracy: 0.0470\n",
      "Epoch 7/50\n",
      "5/5 [==============================] - 0s 92ms/step - loss: 4.3879 - accuracy: 0.0805\n",
      "Epoch 8/50\n",
      "5/5 [==============================] - 0s 90ms/step - loss: 4.4042 - accuracy: 0.0738\n",
      "Epoch 9/50\n",
      "5/5 [==============================] - 0s 94ms/step - loss: 4.3251 - accuracy: 0.0671\n",
      "Epoch 10/50\n",
      "5/5 [==============================] - 0s 94ms/step - loss: 4.2902 - accuracy: 0.0470\n",
      "Epoch 11/50\n",
      "5/5 [==============================] - 0s 94ms/step - loss: 4.2629 - accuracy: 0.0805\n",
      "Epoch 12/50\n",
      "5/5 [==============================] - 0s 90ms/step - loss: 4.1998 - accuracy: 0.1007\n",
      "Epoch 13/50\n",
      "5/5 [==============================] - 0s 93ms/step - loss: 4.1424 - accuracy: 0.0940\n",
      "Epoch 14/50\n",
      "5/5 [==============================] - 0s 99ms/step - loss: 4.0643 - accuracy: 0.1007\n",
      "Epoch 15/50\n",
      "5/5 [==============================] - 0s 96ms/step - loss: 3.9803 - accuracy: 0.0940\n",
      "Epoch 16/50\n",
      "5/5 [==============================] - 0s 92ms/step - loss: 3.8941 - accuracy: 0.0940\n",
      "Epoch 17/50\n",
      "5/5 [==============================] - 0s 92ms/step - loss: 3.8184 - accuracy: 0.1007\n",
      "Epoch 18/50\n",
      "5/5 [==============================] - 0s 92ms/step - loss: 3.7365 - accuracy: 0.1074\n",
      "Epoch 19/50\n",
      "5/5 [==============================] - 0s 91ms/step - loss: 3.6550 - accuracy: 0.0940\n",
      "Epoch 20/50\n",
      "5/5 [==============================] - 0s 91ms/step - loss: 3.5647 - accuracy: 0.1208\n",
      "Epoch 21/50\n",
      "5/5 [==============================] - 0s 96ms/step - loss: 3.4882 - accuracy: 0.1074\n",
      "Epoch 22/50\n",
      "5/5 [==============================] - 0s 96ms/step - loss: 3.3782 - accuracy: 0.1074\n",
      "Epoch 23/50\n",
      "5/5 [==============================] - 0s 95ms/step - loss: 3.2891 - accuracy: 0.1141\n",
      "Epoch 24/50\n",
      "5/5 [==============================] - 0s 90ms/step - loss: 3.1966 - accuracy: 0.1275\n",
      "Epoch 25/50\n",
      "5/5 [==============================] - 0s 92ms/step - loss: 3.1165 - accuracy: 0.1678\n",
      "Epoch 26/50\n",
      "5/5 [==============================] - 0s 93ms/step - loss: 3.0102 - accuracy: 0.1409\n",
      "Epoch 27/50\n",
      "5/5 [==============================] - 0s 92ms/step - loss: 2.9379 - accuracy: 0.2013\n",
      "Epoch 28/50\n",
      "5/5 [==============================] - 0s 92ms/step - loss: 2.8489 - accuracy: 0.2215\n",
      "Epoch 29/50\n",
      "5/5 [==============================] - 0s 92ms/step - loss: 2.7957 - accuracy: 0.1678\n",
      "Epoch 30/50\n",
      "5/5 [==============================] - 0s 90ms/step - loss: 2.7270 - accuracy: 0.1946\n",
      "Epoch 31/50\n",
      "5/5 [==============================] - 0s 93ms/step - loss: 2.6280 - accuracy: 0.2148\n",
      "Epoch 32/50\n",
      "5/5 [==============================] - 0s 90ms/step - loss: 2.5501 - accuracy: 0.2752\n",
      "Epoch 33/50\n",
      "5/5 [==============================] - 0s 96ms/step - loss: 2.4689 - accuracy: 0.2483\n",
      "Epoch 34/50\n",
      "5/5 [==============================] - 0s 92ms/step - loss: 2.3951 - accuracy: 0.2953\n",
      "Epoch 35/50\n",
      "5/5 [==============================] - 0s 91ms/step - loss: 2.3273 - accuracy: 0.3624\n",
      "Epoch 36/50\n",
      "5/5 [==============================] - 0s 98ms/step - loss: 2.2581 - accuracy: 0.3490\n",
      "Epoch 37/50\n",
      "5/5 [==============================] - 0s 93ms/step - loss: 2.1981 - accuracy: 0.4094\n",
      "Epoch 38/50\n",
      "5/5 [==============================] - 0s 92ms/step - loss: 2.1437 - accuracy: 0.4094\n",
      "Epoch 39/50\n",
      "5/5 [==============================] - 0s 92ms/step - loss: 2.0820 - accuracy: 0.4430\n",
      "Epoch 40/50\n",
      "5/5 [==============================] - 0s 94ms/step - loss: 2.0371 - accuracy: 0.5034\n",
      "Epoch 41/50\n",
      "5/5 [==============================] - 0s 91ms/step - loss: 1.9888 - accuracy: 0.5034\n",
      "Epoch 42/50\n",
      "5/5 [==============================] - 0s 92ms/step - loss: 1.9377 - accuracy: 0.5168\n",
      "Epoch 43/50\n",
      "5/5 [==============================] - 0s 92ms/step - loss: 1.8820 - accuracy: 0.5570\n",
      "Epoch 44/50\n",
      "5/5 [==============================] - 0s 90ms/step - loss: 1.9925 - accuracy: 0.5034\n",
      "Epoch 45/50\n",
      "5/5 [==============================] - 0s 100ms/step - loss: 1.9482 - accuracy: 0.5503\n",
      "Epoch 46/50\n",
      "5/5 [==============================] - 0s 90ms/step - loss: 1.8784 - accuracy: 0.5369\n",
      "Epoch 47/50\n",
      "5/5 [==============================] - 0s 90ms/step - loss: 1.8030 - accuracy: 0.5570\n",
      "Epoch 48/50\n",
      "5/5 [==============================] - 0s 88ms/step - loss: 1.7384 - accuracy: 0.6107\n",
      "Epoch 49/50\n",
      "5/5 [==============================] - 0s 90ms/step - loss: 1.6978 - accuracy: 0.6174\n",
      "Epoch 50/50\n",
      "5/5 [==============================] - 0s 92ms/step - loss: 1.6395 - accuracy: 0.6309\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x25eaa1950d0>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X, y, epochs=50, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c3358800",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_text(seed_text, next_words, model, max_sequence_len):\n",
    "    for _ in range(next_words):\n",
    "        token_list = tokenizer.texts_to_sequences([seed_text])[0]\n",
    "        token_list = pad_sequences([token_list], maxlen=max_sequence_len-1, padding='pre')\n",
    "        predicted_probs = model.predict(token_list, verbose=0)[0]\n",
    "        predicted = np.argmax(predicted_probs)\n",
    "        output_word = \"\"\n",
    "        for word, index in tokenizer.word_index.items():\n",
    "            if index == predicted:\n",
    "                output_word = word\n",
    "                break\n",
    "        seed_text += \" \" + output_word\n",
    "    return seed_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f339818f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hello woke up this morning feeling an overwhelming sense of joy\n"
     ]
    }
   ],
   "source": [
    "generated_text = generate_text(\"hello\", 10, model, max_sequence_len)\n",
    "print(generated_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64323778",
   "metadata": {},
   "source": [
    "# 2. Build a Speech to Text model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b1e0fabe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<speech_recognition.AudioFile at 0x25eb1db61d0>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import speech_recognition as sr\n",
    "\n",
    "samp=sr.AudioFile(\"1.wav\")\n",
    "samp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a0a63b8e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Text for the Audio:\n",
      "\n",
      "987654321 0\n"
     ]
    }
   ],
   "source": [
    "recog=sr.Recognizer()\n",
    "\n",
    "with samp as source:\n",
    "    audio=recog.record(samp)\n",
    "\n",
    "    res=recog.recognize_google(audio)\n",
    "print('Text for the Audio:\\n')\n",
    "print(res)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "805a5bdb",
   "metadata": {},
   "source": [
    "# 3. Build a Text to Speech model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "1fcf549a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User text pl >>:Hi, This is your voice assistant. How can I help you?\n"
     ]
    }
   ],
   "source": [
    "from gtts import gTTS\n",
    "import os\n",
    "def text_to_speech(text,language='en',filename='output.mp3'):\n",
    "    tts=gTTS(text=text,lang=language,slow=False)\n",
    "    tts.save(filename)\n",
    "    os.system(f\"start {filename}\")\n",
    "\n",
    "input_text=input('User text pl >>:')\n",
    "text_to_speech(input_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fd1a8fa",
   "metadata": {},
   "source": [
    "# 4. Build a NLP Language model to detect the sentence/word error in the text corpus."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a960ea65",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "391cee1b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package words to\n",
      "[nltk_data]     C:\\Users\\Ramesh\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package words is already up-to-date!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enter the text :I am the keng off the contry. I will rule from now onwords.\n",
      "\n",
      "Misspelled Words:\n",
      "['keng', 'contry', '.', 'onwords', '.']\n"
     ]
    }
   ],
   "source": [
    "# Download the words corpus (if not already downloaded)\n",
    "nltk.download('words')\n",
    "\n",
    "# Sample text with intentional errors\n",
    "text = input(\"Enter the text :\")\n",
    "\n",
    "# Tokenize the text into words\n",
    "tokens = word_tokenize(text)\n",
    "\n",
    "# Get the set of English words from the nltk corpus\n",
    "english_vocab = set(words.words())\n",
    "\n",
    "# Check for misspelled words\n",
    "misspelled_words = [word for word in tokens if word.lower() not in english_vocab]\n",
    "\n",
    "print()\n",
    "\n",
    "# Print misspelled words\n",
    "if len(misspelled_words) > 0:\n",
    "    print(\"Misspelled Words:\")\n",
    "    print(misspelled_words)\n",
    "else:\n",
    "    print(\"No misspelled words found.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e94e31c",
   "metadata": {},
   "source": [
    "# 5. Build a Language model to correct the error in the text."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "532fd238",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Corrected Sentence: Thes are some spelling errors in thiss sentence\n"
     ]
    }
   ],
   "source": [
    "from spellchecker import SpellChecker\n",
    "\n",
    "spell = SpellChecker()\n",
    "\n",
    "# Example sentence with errors\n",
    "sentence_with_errors = \"Thes arre somee speling errrs in thiss sentenc.\"\n",
    "\n",
    "# Split the sentence into words\n",
    "words = sentence_with_errors.split()\n",
    "\n",
    "# Identify misspelled words\n",
    "misspelled = spell.unknown(words)\n",
    "\n",
    "# Correct misspelled words\n",
    "corrected_sentence = \" \".join(spell.correction(word) for word in words)\n",
    "\n",
    "print(\"Corrected Sentence:\", corrected_sentence)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
